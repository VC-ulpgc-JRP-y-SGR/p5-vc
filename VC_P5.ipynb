{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod, ABC\n",
    "from numpy import array\n",
    "\n",
    "class PlateDetector(ABC):\n",
    "    @abstractmethod\n",
    "    def detect(self, img: array) -> list[array]:\n",
    "        pass\n",
    "\n",
    "class PlateMatcher(ABC):\n",
    "    @abstractmethod\n",
    "    def match(self, text : str) -> bool:\n",
    "        pass\n",
    "\n",
    "class TextProcessor(ABC):\n",
    "    @abstractmethod\n",
    "    def process(self, text : str) -> str:\n",
    "        pass\n",
    "\n",
    "class TextExtractor(ABC):\n",
    "    def __init__(self, matcher : PlateMatcher, processor : TextProcessor):\n",
    "        self.matcher = matcher\n",
    "        self.processor = processor\n",
    "\n",
    "    @abstractmethod\n",
    "    def extract(self, img: array) -> str:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor(ABC):\n",
    "    @abstractmethod\n",
    "    def process(self, img: array) -> array:\n",
    "        pass\n",
    "\n",
    "class CannyImageProcessor(ImageProcessor):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def process(self, img: array) -> array:\n",
    "        #apply Canny\n",
    "        import cv2 as cv\n",
    "        canny = cv.Canny(img, self.x, self.y)\n",
    "        return canny\n",
    "\n",
    "class SobelImageProcessor(ImageProcessor):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def process(self, img: array) -> array:\n",
    "        #apply Sobel\n",
    "        import cv2 as cv\n",
    "        sobel = cv.Sobel(img, cv.CV_8U, self.x, self.y, ksize=5)\n",
    "        return sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOPlateDetector(PlateDetector):\n",
    "    def __init__(self, model, category = 0, image_processors = list()):\n",
    "        self.model = model\n",
    "        self.category = category\n",
    "        self.image_processors = image_processors\n",
    "\n",
    "    def detect(self, img):\n",
    "        from ultralytics import YOLO\n",
    "        model = YOLO(self.model)\n",
    "        results = model(img)\n",
    "        cars = []\n",
    "        for x in results:\n",
    "            boxes = x.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                category = int(box.cls[0])\n",
    "                if category == 0:\n",
    "                    img = img[y1:y2, x1:x2]\n",
    "                    for x in self.image_processors:\n",
    "                        img = x.process(img)\n",
    "                    cars.append(img)\n",
    "        return cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LengthPlateMatcher(PlateMatcher):\n",
    "    def match(self, text : str) -> bool:\n",
    "        if len(text) == 7: return True\n",
    "        return False\n",
    "\n",
    "class RegexPlateMatcher(PlateMatcher):\n",
    "    def match(self, text : str) -> bool:\n",
    "        import re\n",
    "        pattern = re.compile(\"^[0-9]{4}([B-D]|[F-H]|[J-N]|[P-T]|[V-Z]){3}$\")\n",
    "        if pattern.match(text):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TesseractTextExtractor(TextExtractor):\n",
    "    def extract(self, img):\n",
    "        import pytesseract\n",
    "        pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract'\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        matcher = RegexPlateMatcher()\n",
    "        if matcher.match(text):\n",
    "            text = self.processor.process(text)\n",
    "            return text\n",
    "        \n",
    "class EasyOCRTextExtractor(TextExtractor):\n",
    "    def extract(self, img):\n",
    "        import easyocr\n",
    "        reader = easyocr.Reader(['es']) \n",
    "        result = reader.readtext(img)\n",
    "        if(len(result) == 0): return \"\"\n",
    "        for x in result:\n",
    "            text = x[1]\n",
    "            text = self.processor.process(text)\n",
    "            if(self.matcher.match(text)):\n",
    "                return text\n",
    "\n",
    "class KerasOCRTextExtractor(TextExtractor):\n",
    "    def extract(self, img):\n",
    "        from keras_ocr.detection import Detector\n",
    "        from keras_ocr.recognition import Recognizer\n",
    "        from keras_ocr import pipeline\n",
    "\n",
    "        detector = Detector()\n",
    "        recognizer = Recognizer()\n",
    "        pipeline = pipeline.Pipeline(detector=detector, recognizer=recognizer)\n",
    "        prediction_groups = pipeline.recognize([img])\n",
    "        for group in prediction_groups:\n",
    "            for word in group:\n",
    "                text = word[0]\n",
    "                text = self.processor.process(text)\n",
    "                if(self.matcher.match(text)):\n",
    "                    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTextProcessor(TextProcessor):\n",
    "    def process(self, text : str) -> str:\n",
    "        text = text.replace(\" \", \"\")\n",
    "        text = text.replace(\"-\", \"\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarPlateDetector:\n",
    "    def __init__(self,  text_extractor : TextExtractor, plate_detector : PlateDetector):\n",
    "        self.plate_detector = plate_detector\n",
    "        self.text_extractor = text_extractor\n",
    "\n",
    "    def detect(self, image : str) -> list[str]:\n",
    "        import cv2 as cv\n",
    "        image = cv.imread(image)\n",
    "        cars = self.plate_detector.detect(image)\n",
    "        return [self.text_extractor.extract(x) for x in cars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ColorThresholdImageProcessor(ImageProcessor):\n",
    "    def __init__(self, lower, upper):\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "    \n",
    "    def process(self, img: array) -> array:\n",
    "        import cv2 as cv\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        mask = cv.inRange(img, self.lower, self.upper)\n",
    "        img = cv.bitwise_and(img, img, mask=mask)\n",
    "        return img\n",
    "\n",
    "class ContoursImageProcessor(ImageProcessor):\n",
    "    def process(self, image: array) -> array:\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "\n",
    "        mask = np.ones(image.shape, dtype=np.uint8) * 255\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "        dilate = thresh\n",
    "\n",
    "        cnts = cv2.findContours(dilate, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area < 300:\n",
    "                x,y,w,h = cv2.boundingRect(c)\n",
    "                mask[y:y+h, x:x+w] = image[y:y+h, x:x+w]\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 142.2ms\n",
      "Speed: 9.8ms preprocess, 142.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0478LFR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 109.2ms\n",
      "Speed: 2.9ms preprocess, 109.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0478LFR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 126.2ms\n",
      "Speed: 3.5ms preprocess, 126.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0478LFR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 103.0ms\n",
      "Speed: 2.4ms preprocess, 103.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0478LFR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 110.0ms\n",
      "Speed: 2.6ms preprocess, 110.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0478LFR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 108.1ms\n",
      "Speed: 2.5ms preprocess, 108.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0478LFR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 111.5ms\n",
      "Speed: 2.5ms preprocess, 111.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0478LFR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 109.5ms\n",
      "Speed: 3.0ms preprocess, 109.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0478LFR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 107.8ms\n",
      "Speed: 3.1ms preprocess, 107.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0478LFR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 107.8ms\n",
      "Speed: 2.6ms preprocess, 107.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0478LFR']\n"
     ]
    }
   ],
   "source": [
    "text_extractor=EasyOCRTextExtractor(\n",
    "    processor=BasicTextProcessor(), \n",
    "    matcher=LengthPlateMatcher()\n",
    ")\n",
    "\n",
    "\n",
    "plate_detector = YOLOPlateDetector(model='plate_recognizer.pt', image_processors=[\n",
    "    ]\n",
    ")\n",
    "\n",
    "detector = CarPlateDetector(\n",
    "    text_extractor,\n",
    "    plate_detector\n",
    ")\n",
    "\n",
    "\n",
    "def  detectImage():\n",
    "    result = detector.detect('./plates/coches2.jpg')\n",
    "    print(result)\n",
    "\n",
    "for x in range(0, 10):\n",
    "    detectImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 242.1ms\n",
      "Speed: 4.4ms preprocess, 242.1ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 384x640 1 License_Plate, 195.7ms\n",
      "Speed: 4.3ms preprocess, 195.7ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 384x640 1 License_Plate, 250.6ms\n",
      "Speed: 3.4ms preprocess, 250.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 License_Plate, 260.2ms\n",
      "Speed: 3.0ms preprocess, 260.2ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 License_Plate, 268.1ms\n",
      "Speed: 8.9ms preprocess, 268.1ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 License_Plate, 282.4ms\n",
      "Speed: 5.6ms preprocess, 282.4ms inference, 18.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 License_Plate, 265.1ms\n",
      "Speed: 4.5ms preprocess, 265.1ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 License_Plate, 250.2ms\n",
      "Speed: 8.7ms preprocess, 250.2ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 License_Plate, 255.8ms\n",
      "Speed: 4.2ms preprocess, 255.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 License_Plate, 261.8ms\n",
      "Speed: 6.0ms preprocess, 261.8ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "\n",
    "text_extractor=EasyOCRTextExtractor(\n",
    "    processor=BasicTextProcessor(), \n",
    "    matcher=LengthPlateMatcher()\n",
    ")\n",
    "\n",
    "plate_detector = YOLOPlateDetector(model='plate_recognizer.pt')\n",
    "\n",
    "detector = CarPlateDetector(\n",
    "    text_extractor,\n",
    "    plate_detector\n",
    ")\n",
    "\n",
    "\n",
    "def  detectImage():\n",
    "    result = detector.detect('./plates/coches2.jpg')\n",
    "\n",
    "\n",
    "threads = [\n",
    "]\n",
    "\n",
    "def add_threads(num_threads=10):\n",
    "    for x in range(0, num_threads):\n",
    "        threads.append(threading.Thread(target=detectImage))\n",
    "    \n",
    "def join_threads():\n",
    "    for x in threads:\n",
    "        x.start()\n",
    "    for x in threads:\n",
    "        x.join()\n",
    "\n",
    "add_threads(10)\n",
    "join_threads()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 License_Plate, 105.6ms\n",
      "Speed: 2.5ms preprocess, 105.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plate detection time: 1.5460870265960693 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "image = cv2.imread('./plates/coches2.jpg')\n",
    "processor = BasicTextProcessor()\n",
    "# matcher = LengthPlateMatcher()\n",
    "matcher = RegexPlateMatcher()\n",
    "detector = YOLOPlateDetector(model='plate_recognizer.pt')\n",
    "extractor = EasyOCRTextExtractor(matcher, processor)\n",
    "start = time.time()\n",
    "plates = detector.detect(image)\n",
    "print(\"plate detection time:\", time.time() - start, \"seconds\")\n",
    "\n",
    "# Dibujar rect치ngulos alrededor de las placas detectadas\n",
    "for plate in plates:\n",
    "    if len(plate) == 5:  # Asegurarse de que haya cinco valores en la tupla\n",
    "        print(plate)\n",
    "        x1, y1, x2, y2, img = plate\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        start = time.time()\n",
    "        detection = extractor.extract(img)\n",
    "        print(\"easyocr reading time:\", time.time() - start, \"seconds\")\n",
    "        if detection == None or detection == '': detection = \"unknown plate\"\n",
    "        cv2.putText(image, str(detection), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Mostrar la imagen con los rect치ngulos dibujados\n",
    "cv2.imshow('Plates Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 License_Plates, 109.6ms\n",
      "Speed: 3.4ms preprocess, 109.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 License_Plate, 101.7ms\n",
      "Speed: 3.2ms preprocess, 101.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 License_Plate, 97.6ms\n",
      "Speed: 2.4ms preprocess, 97.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 License_Plate, 96.4ms\n",
      "Speed: 2.4ms preprocess, 96.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 License_Plate, 96.2ms\n",
      "Speed: 2.7ms preprocess, 96.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 License_Plate, 94.9ms\n",
      "Speed: 2.7ms preprocess, 94.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 License_Plate, 105.5ms\n",
      "Speed: 2.8ms preprocess, 105.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 License_Plate, 103.3ms\n",
      "Speed: 2.3ms preprocess, 103.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 License_Plate, 105.7ms\n",
      "Speed: 2.4ms preprocess, 105.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 License_Plate, 109.7ms\n",
      "Speed: 2.4ms preprocess, 109.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 License_Plate, 111.9ms\n",
      "Speed: 2.5ms preprocess, 111.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb Celda 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret: \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(frame, (width, height))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m plates \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39;49mdetect(frame)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Dibujar rect치ngulos alrededor de las placas detectadas\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m plate \u001b[39min\u001b[39;00m plates:\n",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb Celda 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39multralytics\u001b[39;00m \u001b[39mimport\u001b[39;00m YOLO\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m YOLO(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m results \u001b[39m=\u001b[39m model(img)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m cars \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p5/VC_P5.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m results:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/ultralytics/engine/model.py:101\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, source\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    100\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the 'predict' function with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(source, stream, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/ultralytics/engine/model.py:235\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor:\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor \u001b[39m=\u001b[39m (predictor \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_smart_load(\u001b[39m'\u001b[39m\u001b[39mpredictor\u001b[39m\u001b[39m'\u001b[39m))(overrides\u001b[39m=\u001b[39margs, _callbacks\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks)\n\u001b[0;32m--> 235\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor\u001b[39m.\u001b[39;49msetup_model(model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, verbose\u001b[39m=\u001b[39;49mis_cli)\n\u001b[1;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# only update args if predictor is already setup\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m get_cfg(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39margs, args)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/ultralytics/engine/predictor.py:312\u001b[0m, in \u001b[0;36mBasePredictor.setup_model\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup_model\u001b[39m(\u001b[39mself\u001b[39m, model, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    310\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Initialize YOLO model with given parameters and set it to evaluation mode.\"\"\"\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m AutoBackend(model \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mmodel,\n\u001b[0;32m--> 312\u001b[0m                              device\u001b[39m=\u001b[39mselect_device(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mdevice, verbose\u001b[39m=\u001b[39;49mverbose),\n\u001b[1;32m    313\u001b[0m                              dnn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdnn,\n\u001b[1;32m    314\u001b[0m                              data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata,\n\u001b[1;32m    315\u001b[0m                              fp16\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhalf,\n\u001b[1;32m    316\u001b[0m                              fuse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    317\u001b[0m                              verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m    319\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mdevice  \u001b[39m# update device\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhalf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfp16  \u001b[39m# update half\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/ultralytics/utils/torch_utils.py:143\u001b[0m, in \u001b[0;36mselect_device\u001b[0;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[1;32m    141\u001b[0m     arg \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# revert to CPU\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     s \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCPU (\u001b[39m\u001b[39m{\u001b[39;00mget_cpu_info()\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    144\u001b[0m     arg \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/ultralytics/utils/torch_utils.py:60\u001b[0m, in \u001b[0;36mget_cpu_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcpuinfo\u001b[39;00m  \u001b[39m# pip install py-cpuinfo\u001b[39;00m\n\u001b[1;32m     59\u001b[0m k \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbrand_raw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhardware_raw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39march_string_raw\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# info keys sorted by preference (not all keys always available)\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m info \u001b[39m=\u001b[39m cpuinfo\u001b[39m.\u001b[39;49mget_cpu_info()  \u001b[39m# info dict\u001b[39;00m\n\u001b[1;32m     61\u001b[0m string \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39mget(k[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m k[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m info \u001b[39melse\u001b[39;00m k[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m k[\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m info \u001b[39melse\u001b[39;00m k[\u001b[39m2\u001b[39m], \u001b[39m'\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m string\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m(R)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mCPU \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m@ \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/cpuinfo/cpuinfo.py:2759\u001b[0m, in \u001b[0;36mget_cpu_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2752\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \u001b[39mReturns the CPU info by using the best sources of information for your OS.\u001b[39;00m\n\u001b[1;32m   2754\u001b[0m \u001b[39mReturns the result in a dict\u001b[39;00m\n\u001b[1;32m   2755\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m   2757\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m-> 2759\u001b[0m output \u001b[39m=\u001b[39m get_cpu_info_json()\n\u001b[1;32m   2761\u001b[0m \u001b[39m# Convert JSON to Python with non unicode strings\u001b[39;00m\n\u001b[1;32m   2762\u001b[0m output \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(output, object_hook \u001b[39m=\u001b[39m _utf_to_str)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/cpuinfo/cpuinfo.py:2742\u001b[0m, in \u001b[0;36mget_cpu_info_json\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2740\u001b[0m command \u001b[39m=\u001b[39m [sys\u001b[39m.\u001b[39mexecutable, \u001b[39m__file__\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m--json\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m   2741\u001b[0m p1 \u001b[39m=\u001b[39m Popen(command, stdout\u001b[39m=\u001b[39mPIPE, stderr\u001b[39m=\u001b[39mPIPE, stdin\u001b[39m=\u001b[39mPIPE)\n\u001b[0;32m-> 2742\u001b[0m output \u001b[39m=\u001b[39m p1\u001b[39m.\u001b[39;49mcommunicate()[\u001b[39m0\u001b[39m]\n\u001b[1;32m   2744\u001b[0m \u001b[39mif\u001b[39;00m p1\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2745\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[1;32m   1210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/subprocess.py:2108\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2101\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2102\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2103\u001b[0m                         skip_check_and_raise\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   2104\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(  \u001b[39m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2105\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2106\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfailed to raise TimeoutExpired.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 2108\u001b[0m ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2111\u001b[0m \u001b[39m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2112\u001b[0m \u001b[39m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selector\u001b[39m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('videos/license_plates_fps.mp4')\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) / 2)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) / 2)\n",
    "\n",
    "processor = BasicTextProcessor()\n",
    "# matcher = LengthPlateMatcher()\n",
    "matcher = RegexPlateMatcher()\n",
    "detector = YOLOPlateDetector(model='plate_recognizer.pt')\n",
    "extractor = EasyOCRTextExtractor(matcher, processor)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "    plates = detector.detect(frame)\n",
    "\n",
    "    # Dibujar rect치ngulos alrededor de las placas detectadas\n",
    "    for plate in plates:\n",
    "        if len(plate) == 5:  # Asegurarse de que haya cuatro valores en la tupla\n",
    "            x1, y1, x2, y2, img = plate\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            detection = extractor.extract(img)\n",
    "            if detection == None or detection == '': detection = \"unknown plate\"\n",
    "            cv2.putText(frame, detection, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Plates', frame)\n",
    "    if cv2.waitKey(20) == 27: \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54711ba1bddc392d48ca20e80feaa9b2e23d43069aa8b98ed16355091034ff6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
